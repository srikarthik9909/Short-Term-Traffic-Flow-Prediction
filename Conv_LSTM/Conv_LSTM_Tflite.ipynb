{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Converting the CONV-LSTM Model.h5 to CONV-LSTM Model.tflite"
      ],
      "metadata": {
        "id": "aB20qniyn87O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converts the trained Keras model (.h5) to a TensorFlow Lite format (.tflite) for optimized inference on edge devices."
      ],
      "metadata": {
        "id": "6f7nBRyOpdr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('CONV-LSTM-Model.h5')\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS\n",
        "]\n",
        "converter.experimental_new_converter = True\n",
        "converter._experimental_lower_tensor_list_ops = False\n",
        "tflite_model = converter.convert()"
      ],
      "metadata": {
        "id": "7UQIJm_Dn_O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TFLite Model Prediction"
      ],
      "metadata": {
        "id": "RT5vcOeGpq5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uses the TensorFlow Lite interpreter to load the .tflite model, make predictions on test data, and collect predicted and true values."
      ],
      "metadata": {
        "id": "YHAQPbzIpqpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Conv_LSTM_Model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=\"Conv_LSTM_Model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "predicted_values,true_values=[],[]\n",
        "\n",
        "for i in range(len(X_test_lstm)):\n",
        "    cnn_input_data = np.expand_dims(X_test_cnn[i], axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_details[0]['index'], cnn_input_data)\n",
        "    interpreter.invoke()\n",
        "\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "    predicted_values.append(output_data[0][0])\n",
        "    true_values.append(y_test[i])\n",
        "\n",
        "predicted_values = np.array(predicted_values)\n",
        "true_values = np.array(true_values)"
      ],
      "metadata": {
        "id": "UEipBBHLpeZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions and Evaluation"
      ],
      "metadata": {
        "id": "wPuwBLLUpx9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rescales the predicted and actual values to their original range and creates a DataFrame to compare predictions with actual values."
      ],
      "metadata": {
        "id": "Ck4qcYenp91H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_values_reshaped = predicted_values.reshape(-1, 1)\n",
        "predictions_rescaled = station_scaler.inverse_transform(predicted_values_reshaped).flatten()\n",
        "\n",
        "y_test_reshaped = true_values.reshape(-1, 1)\n",
        "y_test_rescaled = station_scaler.inverse_transform(y_test_reshaped).flatten()\n",
        "\n",
        "results = pd.DataFrame(data={'Predictions': predictions_rescaled, 'Actuals': y_test_rescaled})\n",
        "print(results)"
      ],
      "metadata": {
        "id": "KiUiI0sYp3SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Metrics for TFLite"
      ],
      "metadata": {
        "id": "jO6DjiGwp_Uq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computes RMSE, MAE, and MAPE to evaluate the performance of the optimized TFLite model on test data."
      ],
      "metadata": {
        "id": "8SdAgvSrqCfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opti_rmse = math.sqrt(mean_squared_error(y_test_rescaled, predictions_rescaled))\n",
        "opti_mae = mean_absolute_error(y_test_rescaled, predictions_rescaled)\n",
        "opti_mape = mean_absolute_percentage_error(predictions_rescaled, y_test_rescaled)\n",
        "\n",
        "print(\"Optimized RMSE:\", opti_rmse)\n",
        "print(\"Optimized MAE:\", opti_mae)\n",
        "print(\"Optimized MAPE:\", opti_mape)"
      ],
      "metadata": {
        "id": "1ErIr0lqqCFp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}